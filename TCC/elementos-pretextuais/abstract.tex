\begin{resumo}[Abstract]
\begin{otherlanguage*}{english}
\begin{SingleSpace}
This work presents the application of large-scale language models (LLMs), specifically GPT-4, in automating customer service evaluation, validating its effectiveness through a proof of concept (PoC) implemented in a real environment at Ef√≠ Bank. The initial hypothesis proposed that the LLM could reduce the need for direct human intervention in the classification and analysis of service requests, allowing adjustments to be made by non-IT professionals, such as customer service leaders or quality analysts. The results support this hypothesis, highlighting the flexibility of LLMs in adapting to new demands with simple prompt adjustments. Furthermore, the project demonstrated that automation can perform thousands of analyses at a competitive operational cost, freeing professionals to focus on higher-value activities.
Among the main challenges encountered were the sensitivity of LLMs to prompt formatting and the phenomenon of ``hallucinations," where the model may generate non-existent data when attempting to respond to an inappropriate request. To mitigate these challenges, strategies for refining prompts and normalizing quantitative data were implemented.
The results obtained demonstrate that, in addition to being economically viable, LLMs can overcome the limitations of traditional human analyses in terms of scale and consistency. The project also identified opportunities to apply this technology in other areas of the organization, such as fraud detection and the automation of commercial processes, expanding the strategic impact of cognitive automation within the company.
\end{SingleSpace}

\vspace{\onelineskip}
\textbf{Keywords}: Generative artificial intelligence. Prompt engineering. GPT-4. Large-scale language models. Cognitive automation. ChatGPT. Customer service.

\end{otherlanguage*}

\end{resumo}
